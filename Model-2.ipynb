{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966710b-7e24-4005-9740-d576a0175510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from Excel file with multiple sheets\n",
    "file_path = 'your_dataset.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "lcc_for_PV_columns = ['initial_cost', 'maintenance_cost', 'energy_cost' , 'PV Size']\n",
    "lcc_for_wind_columns = ['full_address', 'Facility square footage', 'Wind Size' ] \n",
    "#If no `installed_cost_per_kw` is provided then it is determined from:\n",
    " #   ```julia\n",
    " #   size_class_to_installed_cost = Dict(\n",
    "  #      \"residential\"=> 6339.0,\n",
    "   #     \"commercial\"=> 4760.0,\n",
    "    #    \"medium\"=> 3137.0,\n",
    "     #   \"large\"=> 2386.0\n",
    "npv_columns = ['Annual Electricity, KWH', 'Annual electricity Peak, KW', 'PV Size','Wind Size', 'Annual electricity cost', '$/kWh','Facility square footage','Operating Shifts','full_address' ]\n",
    "pv_size_columns = ['solar_radiation', 'panel_efficiency', 'installation_cost', 'Operating Shifts', 'Facility square footage', 'full_address', 'dni','Electric Capacity (kW) PV' ]\n",
    "wind_size_columns = ['wind_speed', 'turbine_efficiency', 'land_cost', 'Facility square footage', 'Operating Shifts', 'full_address','Electric Capacity (kW) Wind']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed637dac-227f-4039-8c33-d8fafbc3029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset (example code, adjust as needed)\n",
    "file_path = 'your_dataset.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Define feature sets and target variables\n",
    "feature_sets = {\n",
    "    'LCC_PV': ['initial_cost', 'maintenance_cost', 'energy_cost', 'PV Size'],\n",
    "    'LCC_Wind': ['full_address', 'Facility square footage', 'Wind Size'],\n",
    "    'NPV': ['Annual Electricity, KWH', 'Annual electricity Peak, KW', 'PV Size', 'Wind Size', \n",
    "            'Annual electricity cost', '$/kWh', 'Facility square footage', 'Operating Shifts', 'full_address'],\n",
    "    'PV_Size': ['solar_radiation', 'panel_efficiency', 'installation_cost', 'Operating Shifts', \n",
    "                'Facility square footage', 'full_address', 'dni', 'Electric Capacity (kW) PV'],\n",
    "    'Wind_Size': ['wind_speed', 'turbine_efficiency', 'land_cost', 'Facility square footage', \n",
    "                  'Operating Shifts', 'full_address', 'Electric Capacity (kW) Wind']\n",
    "}\n",
    "\n",
    "# Define corresponding target variables\n",
    "target_variables = {\n",
    "    'LCC_PV': 'lcc_pv_target',   # Replace with your actual target variable name for LCC_PV\n",
    "    'LCC_Wind': 'lcc_wind_target',  # Replace with your actual target variable name for LCC_Wind\n",
    "    'NPV': 'npv_target',          # Replace with your actual target variable name for NPV\n",
    "    'PV_Size': 'pv_size_target',  # Replace with your actual target variable name for PV_Size\n",
    "    'Wind_Size': 'wind_size_target'  # Replace with your actual target variable name for Wind_Size\n",
    "}\n",
    "\n",
    "# Loop through each feature set and train a model\n",
    "for key, features in feature_sets.items():\n",
    "    target = target_variables[key]\n",
    "    \n",
    "    # Check if target variable exists in the dataframe\n",
    "    if target not in df.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    # Prepare the data\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Print feature importances\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    print(f\"Feature importances for {key}:\")\n",
    "    print(importance_df)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb5022-3c1d-4658-9a7e-b10f0f5889e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset (example code, adjust as needed)\n",
    "file_path = 'your_dataset.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Define feature sets and target variables  #more variables will be added or deleted after the discussion in meeting.\n",
    "feature_sets = {\n",
    "    'LCC_PV': ['initial_cost', 'maintenance_cost', 'energy_cost', 'PV Size'],\n",
    "    'LCC_Wind': ['full_address', 'Facility square footage', 'Wind Size'],\n",
    "    'NPV': ['Annual Electricity, KWH', 'Annual electricity Peak, KW', 'PV Size', 'Wind Size', \n",
    "            'Annual electricity cost', '$/kWh', 'Facility square footage', 'Operating Shifts', 'full_address'],\n",
    "    'PV_Size': ['solar_radiation', 'panel_efficiency', 'installation_cost', 'Operating Shifts', \n",
    "                'Facility square footage', 'full_address', 'dni', 'Electric Capacity (kW) PV'],\n",
    "    'Wind_Size': ['wind_speed', 'turbine_efficiency', 'land_cost', 'Facility square footage', \n",
    "                  'Operating Shifts', 'full_address', 'Electric Capacity (kW) Wind']\n",
    "}\n",
    "\n",
    "target_variables = {\n",
    "    'LCC_PV': 'lcc_pv_target',\n",
    "    'LCC_Wind': 'lcc_wind_target',\n",
    "    'NPV': 'npv_target',\n",
    "    'PV_Size': 'pv_size_target',\n",
    "    'Wind_Size': 'wind_size_target'\n",
    "}\n",
    "#before running the model will discuss about if we need to put some mathematical formulation rather than the ramdom forest for any specific factor out of the 5\n",
    "models = {}\n",
    "\n",
    "# Train models for each target variable\n",
    "for key, features in feature_sets.items():\n",
    "    target = target_variables[key]\n",
    "    \n",
    "    if target not in df.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models[key] = model\n",
    "    print(f\"Trained model for {key}\")\n",
    "\n",
    "# Function to make predictions based on user input\n",
    "def predict(location, target_variable, models, feature_sets, df):\n",
    "    if target_variable not in models:\n",
    "        print(f\"Model for {target_variable} is not available.\")\n",
    "        return\n",
    "    \n",
    "    # Filter data for the given location\n",
    "    input_data = df[df['full_address'] == location]\n",
    "    \n",
    "    if input_data.empty:\n",
    "        print(f\"No data available for the location: {location}\")\n",
    "        return\n",
    "    \n",
    "    features = feature_sets[target_variable]\n",
    "    X_input = input_data[features]\n",
    "    \n",
    "    model = models[target_variable]\n",
    "    prediction = model.predict(X_input)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Interactive CLI for user input\n",
    "def main():\n",
    "    print(\"Welcome to the prediction model!\")\n",
    "    \n",
    "    # Get user input for location\n",
    "    location = input(\"Please enter the location: \")\n",
    "    \n",
    "    # Get user input for target variable\n",
    "    print(\"Choose the target variable to predict:\")\n",
    "    print(\"1. LCC_PV\")\n",
    "    print(\"2. LCC_Wind\")\n",
    "    print(\"3. NPV\")\n",
    "    print(\"4. PV_Size\")\n",
    "    print(\"5. Wind_Size\")\n",
    "    \n",
    "    target_choice = input(\"Enter the number corresponding to the target variable: \")# here needs some edition for putting something which will convert the address in cords.#\n",
    "    target_mapping = {\n",
    "        '1': 'LCC_PV',\n",
    "        '2': 'LCC_Wind',\n",
    "        '3': 'NPV',\n",
    "        '4': 'PV_Size',\n",
    "        '5': 'Wind_Size'\n",
    "    }\n",
    "    \n",
    "    target_variable = target_mapping.get(target_choice)\n",
    "    \n",
    "    if not target_variable:\n",
    "        print(\"Invalid choice! Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = predict(location, target_variable, models, feature_sets, df)\n",
    "    \n",
    "    if prediction is not None:\n",
    "        print(f\"The predicted value for {target_variable} at location {location} is: {prediction}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1c590-13ff-483d-aed2-6368d0bc27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset (example code, adjust as needed)\n",
    "file_path = 'your_dataset.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Define feature sets and target variables\n",
    "feature_sets = {\n",
    "    'LCC_PV': ['initial_cost', 'maintenance_cost', 'energy_cost', 'PV Size'],\n",
    "    'LCC_Wind': ['full_address', 'Facility square footage', 'Wind Size'],\n",
    "    'NPV': ['Annual Electricity, KWH', 'Annual electricity Peak, KW', 'PV Size', 'Wind Size', \n",
    "            'Annual electricity cost', '$/kWh', 'Facility square footage', 'Operating Shifts', 'full_address'],\n",
    "    'PV_Size': ['solar_radiation', 'panel_efficiency', 'installation_cost', 'Operating Shifts', \n",
    "                'Facility square footage', 'full_address', 'dni', 'Electric Capacity (kW) PV'],\n",
    "    'Wind_Size': ['wind_speed', 'turbine_efficiency', 'land_cost', 'Facility square footage', \n",
    "                  'Operating Shifts', 'full_address', 'Electric Capacity (kW) Wind']\n",
    "}\n",
    "\n",
    "target_variables = {\n",
    "    'LCC': 'lcc_pv_target',\n",
    "    'LCC': 'lcc_wind_target',\n",
    "    'NPV': 'npv_target',\n",
    "    'PV_Size': 'pv_size_target',\n",
    "    'Wind_Size': 'wind_size_target'\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Train models for each target variable\n",
    "for key, features in feature_sets.items():\n",
    "    target = target_variables[key]\n",
    "    \n",
    "    if target not in df.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models[key] = model\n",
    "    print(f\"Trained model for {key}\")\n",
    "\n",
    "# Function to get feature importances\n",
    "def get_feature_importances(target_variable, models, feature_sets):\n",
    "    if target_variable not in models:\n",
    "        print(f\"Model for {target_variable} is not available.\")\n",
    "        return None\n",
    "    \n",
    "    features = feature_sets[target_variable]\n",
    "    model = models[target_variable]\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False).head(5)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Interactive CLI for user input\n",
    "def main():\n",
    "    print(\"Welcome to the impact analysis model!\")\n",
    "    \n",
    "    # Get user input for location\n",
    "    location = input(\"Please enter the location: \")\n",
    "    \n",
    "    # Get user input for target variable\n",
    "    print(\"Choose the target variable to analyze:\")\n",
    "    print(\"1. LCC_PV\")\n",
    "    print(\"2. LCC_Wind\")\n",
    "    print(\"3. NPV\")\n",
    "    print(\"4. PV_Size\")\n",
    "    print(\"5. Wind_Size\")\n",
    "    \n",
    "    target_choice = input(\"Enter the number corresponding to the target variable: \")\n",
    "    target_mapping = {\n",
    "        '1': 'LCC_PV',\n",
    "        '2': 'LCC_Wind',\n",
    "        '3': 'NPV',\n",
    "        '4': 'PV_Size',\n",
    "        '5': 'Wind_Size'\n",
    "    }\n",
    "    \n",
    "    target_variable = target_mapping.get(target_choice)\n",
    "    \n",
    "    if not target_variable:\n",
    "        print(\"Invalid choice! Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Get feature importances\n",
    "    importance_df = get_feature_importances(target_variable, models, feature_sets)\n",
    "    \n",
    "    if importance_df is not None:\n",
    "        print(f\"Top 5 impacting features for {target_variable}:\")\n",
    "        print(importance_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697858a-67c3-414d-9a5e-b20346900d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/frashid/Downloads/REopt_data_ML_model.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Convert categorical features to numeric using one-hot encoding\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Define all the features and target variables\n",
    "features = df_encoded.columns.difference(['output_PV_size', 'output_Wind_size', 'output_npv', 'output_lcc'])\n",
    "target_variables = ['output_PV_size', 'output_Wind_size', 'output_npv', 'output_lcc']\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Train models for each target variable\n",
    "for target in target_variables:\n",
    "    if target not in df_encoded.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    X = df_encoded[features]\n",
    "    y = df_encoded[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models[target] = model\n",
    "    print(f\"Trained model for {target}\")\n",
    "\n",
    "# Function to get feature importances\n",
    "def get_feature_importances(target_variable, models, features):\n",
    "    if target_variable not in models:\n",
    "        print(f\"Model for {target_variable} is not available.\")\n",
    "        return None\n",
    "    \n",
    "    model = models[target_variable]\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False).head(5)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Display feature importances for each target variable\n",
    "importance_dict = {}\n",
    "for target in target_variables:\n",
    "    importance_df = get_feature_importances(target, models, features)\n",
    "    if importance_df is not None:\n",
    "        importance_dict[target] = importance_df\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Feature Importances for Each Target Variable\", dataframe=pd.concat(importance_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8eafc95-f7a5-41c7-be5c-d54f2b208ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for output_PV_size\n",
      "Trained model for output_Wind_size\n",
      "Trained model for output_npv\n",
      "Trained model for output_lcc\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m importance_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         importance_dict[target] \u001b[38;5;241m=\u001b[39m importance_df\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m; tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importances for Each Target Variable\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat(importance_dict))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/frashid/Downloads/REopt_data_ML_model.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Convert categorical features to numeric using one-hot encoding\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Define all the features and target variables\n",
    "target_variables = ['output_PV_size', 'output_Wind_size', 'output_npv', 'output_lcc']\n",
    "features = df_encoded.columns.difference(target_variables)\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Train models for each target variable\n",
    "for target in target_variables:\n",
    "    if target not in df_encoded.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    X = df_encoded[features]\n",
    "    y = df_encoded[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models[target] = model\n",
    "    print(f\"Trained model for {target}\")\n",
    "\n",
    "# Function to get feature importances\n",
    "def get_feature_importances(target_variable, models, features):\n",
    "    if target_variable not in models:\n",
    "        print(f\"Model for {target_variable} is not available.\")\n",
    "        return None\n",
    "    \n",
    "    model = models[target_variable]\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False).head(5)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Display feature importances for each target variable\n",
    "importance_dict = {}\n",
    "for target in target_variables:\n",
    "    importance_df = get_feature_importances(target, models, features)\n",
    "    if importance_df is not None:\n",
    "        importance_dict[target] = importance_df\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Feature Importances for Each Target Variable\", dataframe=pd.concat(importance_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7fed30-8de3-48f2-af52-971eaad23eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for output_PV_size\n",
      "Trained model for output_Wind_size\n",
      "Trained model for output_npv\n",
      "Trained model for output_lcc\n",
      "Top 5 impacting features for output_PV_size:\n",
      "                                        Feature  Importance\n",
      "38                    output_PV_energy_exported    0.878326\n",
      "30                     input_Site_electric_load    0.036613\n",
      "36  output_Grid_Electricity_Supplied_kWh_annual    0.022136\n",
      "41                  output_Wind_energy_exported    0.010728\n",
      "0                                input_Latitude    0.006664\n",
      "\n",
      "\n",
      "Top 5 impacting features for output_Wind_size:\n",
      "                                        Feature  Importance\n",
      "41                  output_Wind_energy_exported    0.896340\n",
      "30                     input_Site_electric_load    0.034975\n",
      "36  output_Grid_Electricity_Supplied_kWh_annual    0.011861\n",
      "35                    input_Wind_installed_cost    0.008611\n",
      "1                               input_Longitude    0.007895\n",
      "\n",
      "\n",
      "Top 5 impacting features for output_npv:\n",
      "                                 Feature  Importance\n",
      "38             output_PV_energy_exported    0.383643\n",
      "41           output_Wind_energy_exported    0.223699\n",
      "30              input_Site_electric_load    0.117342\n",
      "29  input_Site_demand_charge_cost_per_kw    0.044519\n",
      "33           input_Site_net_billing_rate    0.036264\n",
      "\n",
      "\n",
      "Top 5 impacting features for output_lcc:\n",
      "                                  Feature  Importance\n",
      "30               input_Site_electric_load    0.477945\n",
      "29   input_Site_demand_charge_cost_per_kw    0.345413\n",
      "12  input_Site_building_type_FlatLoad_8_5    0.075885\n",
      "13  input_Site_building_type_FlatLoad_8_7    0.017651\n",
      "38              output_PV_energy_exported    0.017257\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/frashid/Downloads/REopt_data_ML_model.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Convert categorical features to numeric using one-hot encoding\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Define all the features and target variables\n",
    "target_variables = ['output_PV_size', 'output_Wind_size', 'output_npv', 'output_lcc']\n",
    "features = df_encoded.columns.difference(target_variables)\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Train models for each target variable\n",
    "for target in target_variables:\n",
    "    if target not in df_encoded.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    X = df_encoded[features]\n",
    "    y = df_encoded[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models[target] = model\n",
    "    print(f\"Trained model for {target}\")\n",
    "\n",
    "# Function to get feature importances\n",
    "def get_feature_importances(target_variable, models, features):\n",
    "    if target_variable not in models:\n",
    "        print(f\"Model for {target_variable} is not available.\")\n",
    "        return None\n",
    "    \n",
    "    model = models[target_variable]\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False).head(5)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Display feature importances for each target variable\n",
    "importance_dict = {}\n",
    "for target in target_variables:\n",
    "    importance_df = get_feature_importances(target, models, features)\n",
    "    if importance_df is not None:\n",
    "        print(f\"Top 5 impacting features for {target}:\")\n",
    "        print(importance_df)\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9686eb-96d8-44b1-af8d-2831799fc5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for output_PV_size\n",
      "Trained model for output_Wind_size\n",
      "Trained model for output_npv\n",
      "Trained model for output_lcc\n",
      "Top 5 impacting features for output_PV_size:\n",
      "                                        Feature  Importance\n",
      "36                    output_PV_energy_exported    0.877074\n",
      "28                     input_Site_electric_load    0.040840\n",
      "34  output_Grid_Electricity_Supplied_kWh_annual    0.021165\n",
      "39                  output_Wind_energy_exported    0.012336\n",
      "32                         input_Site_roofspace    0.006909\n",
      "\n",
      "\n",
      "Top 5 impacting features for output_Wind_size:\n",
      "                                        Feature  Importance\n",
      "39                  output_Wind_energy_exported    0.898149\n",
      "28                     input_Site_electric_load    0.035791\n",
      "34  output_Grid_Electricity_Supplied_kWh_annual    0.013612\n",
      "33                    input_Wind_installed_cost    0.010175\n",
      "4                          input_Site_NEM_limit    0.005869\n",
      "\n",
      "\n",
      "Top 5 impacting features for output_npv:\n",
      "                                 Feature  Importance\n",
      "36             output_PV_energy_exported    0.381759\n",
      "39           output_Wind_energy_exported    0.238431\n",
      "28              input_Site_electric_load    0.113650\n",
      "27  input_Site_demand_charge_cost_per_kw    0.043459\n",
      "31           input_Site_net_billing_rate    0.041203\n",
      "\n",
      "\n",
      "Top 5 impacting features for output_lcc:\n",
      "                                  Feature  Importance\n",
      "28               input_Site_electric_load    0.481990\n",
      "27   input_Site_demand_charge_cost_per_kw    0.342834\n",
      "10  input_Site_building_type_FlatLoad_8_5    0.079248\n",
      "11  input_Site_building_type_FlatLoad_8_7    0.017716\n",
      "36              output_PV_energy_exported    0.017233\n",
      "\n",
      "\n",
      "Welcome to the prediction model!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the latitude:  38.27428846\n",
      "Please enter the longitude:  -102.7993766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output_PV_size: 5.54\n",
      "Predicted output_Wind_size: 35.63\n",
      "Predicted output_npv: 16487.6633\n",
      "Predicted output_lcc: 567656.2261000001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/frashid/Downloads/REopt_data_ML_model.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Convert categorical features to numeric using one-hot encoding\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Define all the features and target variables\n",
    "target_variables = ['output_PV_size', 'output_Wind_size', 'output_npv', 'output_lcc']\n",
    "features = df_encoded.columns.difference(target_variables)\n",
    "\n",
    "# Exclude 'input_Latitude' and 'input_Longitude' from features for training\n",
    "features = features.difference(['input_Latitude', 'input_Longitude'])\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Train models for each target variable\n",
    "for target in target_variables:\n",
    "    if target not in df_encoded.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    X = df_encoded[features]\n",
    "    y = df_encoded[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models[target] = model\n",
    "    print(f\"Trained model for {target}\")\n",
    "\n",
    "# Function to get feature importances\n",
    "def get_feature_importances(target_variable, models, features):\n",
    "    if target_variable not in models:\n",
    "        print(f\"Model for {target_variable} is not available.\")\n",
    "        return None\n",
    "    \n",
    "    model = models[target_variable]\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False).head(5)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Display feature importances for each target variable\n",
    "importance_dict = {}\n",
    "for target in target_variables:\n",
    "    importance_df = get_feature_importances(target, models, features)\n",
    "    if importance_df is not None:\n",
    "        importance_dict[target] = importance_df\n",
    "        print(f\"Top 5 impacting features for {target}:\")\n",
    "        print(importance_df)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Function to predict values based on user input coordinates\n",
    "def predict_for_coordinates(models, features, input_data):\n",
    "    input_df = pd.DataFrame([input_data], columns=features)\n",
    "    predictions = {}\n",
    "    for target, model in models.items():\n",
    "        prediction = model.predict(input_df)\n",
    "        predictions[target] = prediction[0]\n",
    "    return predictions\n",
    "\n",
    "# Interactive CLI for user input\n",
    "def main():\n",
    "    print(\"Welcome to the prediction model!\")\n",
    "    \n",
    "    # Get user input for coordinates\n",
    "    latitude = float(input(\"Please enter the latitude: \"))\n",
    "    longitude = float(input(\"Please enter the longitude: \"))\n",
    "    \n",
    "    # Prepare the input data dictionary\n",
    "    input_data = {\n",
    "        'input_Latitude': latitude,\n",
    "        'input_Longitude': longitude\n",
    "    }\n",
    "    \n",
    "    # Fill missing features with zeros\n",
    "    for feature in features:\n",
    "        if feature not in input_data:\n",
    "            input_data[feature] = 0\n",
    "    \n",
    "    # Predict values\n",
    "    predictions = predict_for_coordinates(models, features, input_data)\n",
    "    \n",
    "    # Display predictions\n",
    "    for target, prediction in predictions.items():\n",
    "        print(f\"Predicted {target}: {prediction}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8580839-f1c8-48d6-8f08-f4a113a2b963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for output_PV_size\n",
      "Trained model for output_Wind_size\n",
      "Trained model for output_npv\n",
      "Trained model for output_lcc\n",
      "Welcome to the prediction model!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the latitude:  48.45358183\n",
      "Please enter the longitude:  -107.649841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the target variable to analyze:\n",
      "1. output_PV_size\n",
      "2. output_Wind_size\n",
      "3. output_npv\n",
      "4. output_lcc\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to the target variable:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top impacting features for output_lcc:\n",
      "                                        Feature  Importance\n",
      "30                     input_Site_electric_load    0.481099\n",
      "29         input_Site_demand_charge_cost_per_kw    0.344049\n",
      "12        input_Site_building_type_FlatLoad_8_5    0.081837\n",
      "13        input_Site_building_type_FlatLoad_8_7    0.016868\n",
      "38                    output_PV_energy_exported    0.015447\n",
      "35                    input_Wind_installed_cost    0.007775\n",
      "31          input_Site_electricity_cost_per_kwh    0.006414\n",
      "36  output_Grid_Electricity_Supplied_kWh_annual    0.005448\n",
      "41                  output_Wind_energy_exported    0.005267\n",
      "1                               input_Longitude    0.005257\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/frashid/Downloads/REopt_data_ML_model.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# Combine data from all sheets into a single DataFrame\n",
    "data_list = []\n",
    "for sheet in sheets:\n",
    "    data = pd.read_excel(xls, sheet_name=sheet)\n",
    "    data_list.append(data)\n",
    "df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Convert categorical features to numeric using one-hot encoding\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Define all the features and target variables\n",
    "target_variables = ['output_PV_size', 'output_Wind_size', 'output_npv', 'output_lcc']\n",
    "features = df_encoded.columns.difference(target_variables)\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Train models for each target variable\n",
    "for target in target_variables:\n",
    "    if target not in df_encoded.columns:\n",
    "        print(f\"Target variable '{target}' not found in the dataset.\")\n",
    "        continue\n",
    "    \n",
    "    X = df_encoded[features]\n",
    "    y = df_encoded[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    models[target] = model\n",
    "    print(f\"Trained model for {target}\")\n",
    "\n",
    "# Function to get feature importances\n",
    "def get_feature_importances(model, features):\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Function to predict and display feature importances for a given target variable\n",
    "def predict_and_display_importances(models, features, target_variable):\n",
    "    if target_variable not in models:\n",
    "        print(f\"Model for {target_variable} is not available.\")\n",
    "        return None\n",
    "    \n",
    "    model = models[target_variable]\n",
    "    importance_df = get_feature_importances(model, features)\n",
    "    \n",
    "    print(f\"Top impacting features for {target_variable}:\")\n",
    "    print(importance_df.head(10))  # Display top 10 features\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Interactive CLI for user input\n",
    "def main():\n",
    "    print(\"Welcome to the prediction model!\")\n",
    "    \n",
    "    # Get user input for coordinates\n",
    "    latitude = float(input(\"Please enter the latitude: \"))\n",
    "    longitude = float(input(\"Please enter the longitude: \"))\n",
    "    \n",
    "    # Prepare the input data dictionary\n",
    "    input_data = {\n",
    "        'input_Latitude': latitude,\n",
    "        'input_Longitude': longitude\n",
    "    }\n",
    "    \n",
    "    # Fill missing features with zeros\n",
    "    for feature in features:\n",
    "        if feature not in input_data:\n",
    "            input_data[feature] = 0\n",
    "    \n",
    "    # Get user input for target variable\n",
    "    print(\"Choose the target variable to analyze:\")\n",
    "    print(\"1. output_PV_size\")\n",
    "    print(\"2. output_Wind_size\")\n",
    "    print(\"3. output_npv\")\n",
    "    print(\"4. output_lcc\")\n",
    "    \n",
    "    target_choice = input(\"Enter the number corresponding to the target variable: \")\n",
    "    target_mapping = {\n",
    "        '1': 'output_PV_size',\n",
    "        '2': 'output_Wind_size',\n",
    "        '3': 'output_npv',\n",
    "        '4': 'output_lcc'\n",
    "    }\n",
    "    \n",
    "    target_variable = target_mapping.get(target_choice)\n",
    "    \n",
    "    if not target_variable:\n",
    "        print(\"Invalid choice! Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Predict and display feature importances for the selected target variable\n",
    "    predict_and_display_importances(models, features, target_variable)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0524371-4eb3-4224-a77c-48bafb1ab748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
